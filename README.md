# üåç EcoStream AI : M√©t√©o & Pr√©diction Temps R√©el

**EcoStream AI** est une solution Big Data de surveillance climatique int√©grant une cha√Æne de traitement compl√®te : streaming de donn√©es en temps r√©el, intelligence artificielle pr√©dictive et visualisation analytique.

Le syst√®me collecte les donn√©es de **59 stations m√©t√©orologiques** mondiales, les traite via **Apache Kafka**, pr√©dit la courbe de temp√©rature pour les prochaines 24 heures gr√¢ce √† un mod√®le **XGBoost**, et stocke le tout dans une base de donn√©es **InfluxDB**.

---

## Architecture Technique

Le projet repose sur une architecture moderne orient√©e √©v√©nements (Event-Driven Architecture) :

* **Source de Donn√©es :**
    -  Simulation de capteurs via l'API **Open-Meteo**.
    -  Couverture : 59 villes majeures (Afrique, Europe, Asie, Am√©riques, Oc√©anie).
* **Transport (Streaming) :**
    - **Apache Kafka** (Mode KRaft, sans ZooKeeper).
    - S√©rialisation Avro via **Schema Registry**.
* **Intelligence Artificielle :**
    - Mod√®le **XGBoost (Multi-Output Regressor)**.
    - Capacit√© : Pr√©dit une courbe compl√®te de 24 points (heure par heure) pour J+1.
* **Stockage (Time Series) :**
    - **InfluxDB** : Base de donn√©es optimis√©e pour les s√©ries temporelles.
    - Persistance des donn√©es r√©elles et des pr√©dictions.
* **Visualisation :**
    - Dashboard **Streamlit** style "SaaS/Monitoring".
    - Connexion directe √† la base de donn√©es.

---

##  Technologies Utilis√©es

* **Apache Kafka** (KRaft) & **Confluent Schema Registry**
* **XGBoost** (Machine Learning)
* **InfluxDB** (Time Series Database)
* **Streamlit** & **Altair** (Data Viz)
* **Docker** & **Docker Compose**
* **Python 3.9+** (Pandas, Scikit-learn)

---

##  Pr√©-requis

* **Docker Desktop** (avec Docker Compose).
* **Python 3.9** ou sup√©rieur.
* Connexion Internet (pour l'API m√©t√©o).

###  Installation des D√©pendances Python
```bash
pip install confluent-kafka influxdb-client streamlit pandas scikit-learn xgboost requests altair  
```
---

###  Guide de D√©marrage
Lancer l‚ÄôInfrastructure (Docker)
D√©marre Kafka, Schema Registry, Kafdrop et InfluxDB :

```bash
docker-compose up -d
```

Initialiser l‚ÄôIA (√Ä faire une seule fois)
√âtape A ‚Äî T√©l√©charger l‚Äôhistorique m√©t√©o (3 mois)

```bash
python scripts/fetch_real_history.py
```

√âtape B ‚Äî Entra√Æner le mod√®le IA Cette √©tape g√©n√®re le fichier weather_model.pkl.

```bash
python src/models/train_weather_model.py
```

Lancer l‚ÄôApplication Compl√®te
Le script d‚Äôautomatisation d√©marre le producteur Kafka, le service de pr√©diction et le dashboard Streamlit simultan√©ment.

Double-cliquez sur 
```bash 
run.bat 
```


Projet r√©alis√© dans le cadre du module Big Data - ENSAO
