# üåç EcoStream AI ‚Äî M√©t√©o & Pr√©diction Temps R√©el

**EcoStream AI** est une solution Big Data temps r√©el de surveillance climatique int√©grant une cha√Æne compl√®te de traitement : ingestion de flux, intelligence artificielle pr√©dictive et visualisation analytique.

Le syst√®me collecte des donn√©es m√©t√©o issues de **59 stations mondiales**, les diffuse via **Apache Kafka**, pr√©dit la temp√©rature horaire des prochaines **24 heures** gr√¢ce √† un mod√®le **XGBoost**, et stocke les donn√©es r√©elles ainsi que les pr√©dictions dans une base **InfluxDB**.

Un dashboard **Streamlit** permet le suivi et l‚Äôanalyse en temps r√©el.

---

## ‚ú® Fonctionnalit√©s Cl√©s

* **Ingestion temps r√©el** de donn√©es m√©t√©orologiques (Streaming Kafka).
* **Architecture Event-Driven** (Kafka en mode KRaft, sans ZooKeeper).
* **Pr√©diction multi-horizon (24h)** par station m√©t√©o.
* **Mod√®le IA XGBoost** ‚Äì Multi-Output Regression.
* **Stockage optimis√©** s√©ries temporelles avec **InfluxDB**.
* **Comparaison** valeurs r√©elles vs pr√©dictions.
* **Dashboard interactif** type SaaS / Monitoring.

---

## üèóÔ∏è Architecture Technique

Le projet repose sur une architecture moderne orient√©e √©v√©nements :

### 1Ô∏è‚É£ Source de Donn√©es
* Simulation de capteurs via l‚ÄôAPI **Open-Meteo**.
* Couverture : 59 villes majeures (Afrique, Europe, Asie, Am√©riques, Oc√©anie).

### 2Ô∏è‚É£ Transport & Streaming
* **Apache Kafka** (Mode KRaft).
* S√©rialisation des messages avec **Avro**.
* Gestion des sch√©mas via **Schema Registry**.
* Visualisation des topics avec **Kafdrop**.

### 3Ô∏è‚É£ Intelligence Artificielle
* Mod√®le **XGBoost (Multi-Output Regressor)**.
* Entra√Æn√© sur plusieurs mois d‚Äôhistorique m√©t√©o.
* G√©n√®re une courbe compl√®te de temp√©rature (24 points) pour J+1.

### 4Ô∏è‚É£ Stockage
* **InfluxDB** (Base Time Series).
* Stockage des donn√©es m√©t√©o r√©elles et des donn√©es pr√©dites.

### 5Ô∏è‚É£ Visualisation
* Dashboard **Streamlit**.
* Lecture directe depuis InfluxDB.
* KPIs, courbes temporelles et suivi des pr√©dictions.

---

## üß∞ Technologies Utilis√©es

* **Apache Kafka** (KRaft) & **Confluent Schema Registry**
* **XGBoost** (Machine Learning)
* **InfluxDB** (Time Series Database)
* **Streamlit** & **Altair** (Data Viz)
* **Docker** & **Docker Compose**
* **Python 3.9+** (Pandas, Scikit-learn)

---

## üõ†Ô∏è Pr√©-requis

* **Docker Desktop** (avec Docker Compose).
* **Python 3.9** ou sup√©rieur.
* Connexion Internet (pour l'API m√©t√©o).

### üì¶ Installation des D√©pendances Python
```bash
pip install confluent-kafka influxdb-client streamlit pandas scikit-learn xgboost requests altair  

---

### üöÄ Guide de D√©marrage
1Ô∏è‚É£ Lancer l‚ÄôInfrastructure (Docker)
D√©marre Kafka, Schema Registry, Kafdrop et InfluxDB :

```bash
docker-compose up -d

2Ô∏è‚É£ Initialiser l‚ÄôIA (√Ä faire une seule fois)
√âtape A ‚Äî T√©l√©charger l‚Äôhistorique m√©t√©o (3 mois)

```bash
python scripts/fetch_real_history.py

√âtape B ‚Äî Entra√Æner le mod√®le IA Cette √©tape g√©n√®re le fichier weather_model.pkl.

```bash
python src/models/train_weather_model.py

3Ô∏è‚É£ Lancer l‚ÄôApplication Compl√®te
Le script d‚Äôautomatisation d√©marre le producteur Kafka, le service de pr√©diction et le dashboard Streamlit simultan√©ment.

‚û°Ô∏è Double-cliquez sur run.bat


Projet r√©alis√© dans le cadre du module Big Data - ENSAO